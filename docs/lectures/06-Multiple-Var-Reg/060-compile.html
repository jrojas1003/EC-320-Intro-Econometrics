<!DOCTYPE html>
<html lang="en"><head>
<link href="../../UO-icon.png" rel="icon" type="image/png">
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.39">

  <meta name="author" content="Jose Rojas-Fallas">
  <meta name="dcterms.date" content="2025-01-01">
  <title>EC 320 - Intro. Econometrics – Multiple Variable Regression Analysis</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-1cd891783a50ca476ba011a5a92b8989.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-position="left" class="quarto-title-block center">
  <h1 class="title">Multiple Variable Regression Analysis</h1>
  <p class="subtitle">EC 320 - Introduction to Econometrics</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Jose Rojas-Fallas 
</div>
</div>
</div>

  <p class="date">2025</p>
</section>
<section>
<section id="prologue" class="title-slide slide level1 inverse note center">
<h1>Prologue</h1>

</section>
<section id="quick-recap" class="slide level2">
<h2>Quick Recap</h2>
<p><span class="hi">The Regression Model</span></p>
<p>We can estimate the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> by estimating a <span class="hi">regression model:</span></p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_i + u_i\]</span></p>
<ul>
<li><p><span class="math inline">\(Y_i\)</span> is the outcome variable.</p></li>
<li><p><span class="math inline">\(X_i\)</span> is the treatment variable (continuous).</p></li>
<li><p><span class="math inline">\(\beta_0\)</span> is the <span class="hi">intercept</span> parameter. <span class="math inline">\(\mathop{\mathbb{E}}\left[ {Y_i | X_i=0} \right] = \beta_0\)</span></p></li>
<li><p><span class="math inline">\(\beta_1\)</span> is the <span class="hi">slope</span> parameter, which under the correct causal setting represents marginal change in <span class="math inline">\(X_i\)</span>’s effect on <span class="math inline">\(Y_i\)</span>. <span class="math inline">\(\frac{\partial Y_i}{\partial X_i} = \beta_1\)</span></p></li>
<li><p><span class="math inline">\(u_i\)</span> is an error term including all other (omitted) factors affecting <span class="math inline">\(Y_i\)</span>.</p></li>
</ul>
</section>
<section id="the-error-term" class="slide level2">
<h2>The error term</h2>
<p><span class="math inline">\(u_i\)</span> is quite special</p>
<p><br></p>
<p>Consider the <span class="note">data generating process</span> of variable <span class="math inline">\(Y_i\)</span>,</p>
<ul>
<li><span class="math inline">\(u_i\)</span> captures <span class="note"><em>all unobserved relationships</em></span> that explain variation in <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><br></p>
<p>Some error will exist in all models, <span class="fragment">our aim is to <span class="hi"><em>minimize error</em></span> under a set of constraints.</span> <span class="fragment">This error is the price we are willing to accept for simplified model</span></p>
</section>
<section id="the-error-term-1" class="slide level2" data-visibility="uncounted">
<h2>The error term</h2>
<p><span class="hi">Five</span> items contribute to the existence of the disturbance term:</p>
<p><span class="hi">1.</span> Omission of explanatory variables</p>
<p><span class="hi">2.</span> Aggregation of Variables</p>
<p><span class="hi">3.</span> Model misspecificiation</p>
<p><span class="hi">4.</span> Functional misspecificiation</p>
<p><span class="hi">5.</span> Measurement error</p>
</section>
<section id="running-regressions" class="slide level2">
<h2>Running regressions</h2>
<p>Using an estimator with data on <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span>, we can estimate a <span class="hi">fitted regression line:</span></p>
<p><span class="math display">\[
\hat{Y}_{i} = \hat{\beta}_{0} + \hat{\beta}_{1} X_i
\]</span></p>
<ul>
<li><span class="math inline">\(\hat{Y}_{i}\)</span> is the <span class="hi">fitted value</span> of <span class="math inline">\(Y_i\)</span>.</li>
<li><span class="math inline">\(\hat{\beta}_{0}\)</span> is the <span class="hi">estimated intercept</span>.</li>
<li><span class="math inline">\(\hat{\beta}_{1}\)</span> is the <span class="hi">estimated slope</span>.</li>
</ul>
<div class="fragment">
<p>This procedure produces misses, known as <span class="hi">residuals</span>, <span class="math inline">\(Y_{i} - \hat{Y}_{i}\)</span></p>
</div>
</section>
<section id="gauss-markov-theorem" class="slide level2">
<h2>Gauss-Markov Theorem</h2>
<blockquote>
<p>OLS is the <span class="hi">Best Linear Unbiased Estimator</span> (<span class="hii">BLUE</span>) when the following assumptions hold:</p>
</blockquote>
<p><span class="note">A1.</span> <span class="hi">Linearity:</span> The population relationship is <span class="note"><em>linear in parameters</em></span> with an additive error term.</p>
<p><span class="note">A2.</span> <span class="hi">Sample Variation:</span> There is variation in <span class="math inline">\(X\)</span>.</p>
<p><span class="note">A3.</span> <span class="hi">Exogeniety:</span> The <span class="math inline">\(X\)</span> variable is <span class="note">exogenous</span></p>
<p><span class="note">A4.</span> <span class="hi">Homoskedasticity:</span> The error term has the same variance for each value of the independent variable</p>
<p><span class="note">A5.</span> <span class="hi">Non-autocorrelation:</span> The values of error terms have independent distributions</p>
</section>
<section id="section" class="slide level2">
<h2></h2>
<div class="vertical-center">
<p><em>Consider the following example.</em></p>
</div>
</section></section>
<section>
<section id="ex.-effect-of-class-sizes-on-test-scores" class="title-slide slide level1 inverse note center">
<h1>Ex. Effect of Class Sizes on Test Scores</h1>

</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="vertical-center">
<dl>
<dt><span class="note">Empirical question:</span></dt>
<dd>
<p>What improvement do smaller class sizes have on student test scores, if any?</p>
</dd>
</dl>
</div>
</section>
<section id="ex.-effect-of-class-sizes-on-test-scores-1" class="slide level2">
<h2><span class="ex">Ex.</span> <span class="hi">Effect of class sizes on test scores</span></h2>
<p>Estimate effect of class size on test scores with the following:</p>
<p><span class="math display">\[
\text{Scores}_i = \beta_0 + \beta_1 \text{Class Size}_i + u_i
\]</span></p>
<p><br></p>
<div class="fragment">
<p><span class="hi">Data:</span> Test performance and class across school districts in MA</p>
<ul>
<li>Scores: 4th grade test scores agg. across reading, math, and science</li>
<li>Class size: Ratio of number of students to teachers</li>
</ul>
<p><br></p>
</div>
<div class="fragment">
<p>Always plot your data first</p>
</div>
</section>
<section class="slide level2">


<img data-src="images/ex-raw-data.png" class="quarto-figure quarto-figure-center r-stretch"><p><span class="hi align-left">Raw Data</span></p>
</section>
<section class="slide level2">


<img data-src="images/ex-raw-linear.png" class="quarto-figure quarto-figure-center r-stretch"><p><span class="hi align-left">Fitting OLS</span></p>
</section>
<section id="ex.-effect-of-class-sizes-on-test-scores-2" class="slide level2">
<h2><span class="ex">Ex.</span> <span class="hi">Effect of class sizes on test scores</span></h2>
<p>Estimate effect of class size on test scores with the following:</p>
<p><span class="math display">\[
\text{Scores}_i = \beta_0 + \beta_1 \text{Class Size}_i + u_i
\]</span></p>
<p><br></p>
<p><span class="note">Q.</span> <em>How might smaller class sizes influence test scores?</em></p>
<div class="fragment">
<p><span class="note">A.</span> More personalized teaching, less classroom disruptions etc.</p>
</div>
<div class="fragment">
<p><br></p>
<p><span class="note">Q.</span> <em>What sign would we expect on <span class="math inline">\(\beta_1\)</span>?</em></p>
</div>
<div class="fragment">
<p><span class="note">A.</span></p>
<p><span class="math display">\[
\beta_1 &lt; 0
\]</span></p>
</div>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<p>Smaller class sizes (<span class="hi">X</span>) increases test scores (<span class="hi">Y</span>) <br> <br></p>

<img data-src="images/dag-xy.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="ex.-effect-of-class-sizes-on-test-scores-3" class="slide level2" data-visibility="uncounted">
<h2><span class="ex">Ex.</span> <span class="hi">Effect of class sizes on test scores</span></h2>
<p>Estimate effect of class size on test scores with the following:</p>
<p><span class="math display">\[
\text{Scores}_i = \beta_0 + \beta_1 \text{Class Size}_i + u_i
\]</span></p>
<p><br></p>
<p><span class="note">Q.</span> <em>Do we think <span class="math inline">\(\beta_1\)</span> will be a good guess of the underlying population parameter?</em></p>
<div class="fragment">
<p><span class="note">A.</span> In <span class="math inline">\(u_i\)</span>, several variables are correlated with class size and test scores</p>
<p><span class="fragment">Such as…</span> <span class="fragment hi">school funding</span><span class="fragment">, which might affect:</span></p>
</div>
<div class="fragment">
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Textbooks</li>
<li>Computers</li>
</ul>
</div><div class="column" style="width:50%;">
<ul>
<li>Teacher salary</li>
<li>Attract high income parents</li>
</ul>
</div></div>
</div>
</section>
<section id="section-3" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Smaller class sizes (<span class="hi">X</span>) increases test scores (<span class="hi">Y</span>) <br> <br></p>

<img data-src="images/dag-xy.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-4" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Smaller class sizes (<span class="hi">X</span>) increases test scores (<span class="hi">Y</span>) along with greater school funding (<span class="hi">U</span>)</p>

<img data-src="images/dag-xyu-01.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-5" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Smaller class sizes (<span class="hi">X</span>) increases test scores (<span class="hi">Y</span>) along with greater school funding (<span class="hi">U</span>). And, school funding (<span class="hi">U</span>) is correlated with test scores (<span class="hi">X</span>).</p>

<img data-src="images/dag-xyu-02.png" class="quarto-figure quarto-figure-center r-stretch"><div class="fragment">
<p><em>Any unobserved variable</em> that connects a <span class="note">backdoor path</span> between class size (<span class="hi">X</span>) and test scores (<span class="hi">Y</span>) will <span class="hi">bias</span> our <span class="note">point estimate</span> of <span class="math inline">\(\beta_1\)</span>.</p>
</div>
</section>
<section id="section-6" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p><em>Any unobserved variable</em> that connects a <span class="note">backdoor path</span> between class size (<span class="hi">X</span>) and test scores (<span class="hi">Y</span>) will <span class="hi">bias</span> our <span class="note">point estimate</span> of <span class="math inline">\(\beta_1\)</span>. <span class="fragment note">Why?</span></p>
<p><br></p>
<p><span class="note">A1.</span> Linearity</p>
<p><span class="note">A2.</span> Sample Variation</p>
<p><span class="note">A3.</span> Exogeniety</p>
<p><span class="note">A4.</span> Homoskedasticity</p>
<p><span class="note">A5.</span> Non-autocorrelation</p>
<p><span class="note">A6.</span> Normality</p>
</section>
<section id="section-7" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p><em>Any unobserved variable</em> that connects a <span class="note">backdoor path</span> between class size (<span class="hi">X</span>) and test scores (<span class="hi">Y</span>) will <span class="hi">bias</span> our <span class="note">point estimate</span> of <span class="math inline">\(\beta_1\)</span>. <span class="note">Why?</span></p>
<p><br></p>
<p><span class="note">A1.</span> Linearity</p>
<p><span class="note">A2.</span> Sample Variation</p>
<p><span class="note">A3.</span> <span class="hi-red">Exogeniety: The <span class="math inline">\(X\)</span> variable is exogenous</span></p>
<p><span class="note">A4.</span> Homoskedasticity</p>
<p><span class="note">A5.</span> Non-autocorrelation</p>
<p><span class="note">A6.</span> Normality</p>
</section>
<section id="section-8" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p><em>Any unobserved variable</em> that connects a <span class="note">backdoor path</span> between class size (<span class="hi">X</span>) and test scores (<span class="hi">Y</span>) will <span class="hi">bias</span> our <span class="note">point estimate</span> of <span class="math inline">\(\beta_1\)</span>. <span class="note">Why?</span></p>
<p><br></p>
<p><span class="note">A.</span> Because is <span class="hi-red">violates the exogeniety assumption</span></p>
<p><span class="math display">\[
\mathop{\mathbb{E}}\left( u|\text{Class Size} \right) \neq 0
\]</span></p>
<p>Correlation between class size and school funding (<span class="math inline">\(u_i\)</span>) is not zero.</p>
</section>
<section id="section-9" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Graphically… Valid exogeniety, <em>i.e.</em>, <span class="math inline">\(\mathop{\mathbb{E}}\left( u \mid X \right) = 0\)</span></p>
<p><br></p>

<img data-src="images/sim-data-valid-exo.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-10" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Graphically… Invalid exogeniety, <em>i.e.</em>, <span class="math inline">\(\mathop{\mathbb{E}}\left( u \mid X \right) \neq 0\)</span></p>
<p><br></p>

<img data-src="images/sim-data-no-exo.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-11" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>What the actual data looks like:</p>

<img data-src="images/actual-data.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">

<div class="vertical-center">
<p>This violation has a name. <span class="fragment">We call it <span class="note">omitted variable bias</span></span></p>
</div>
</section></section>
<section>
<section id="omitted-variable-bias" class="title-slide slide level1 inverse note center">
<h1>Omitted Variable Bias</h1>

</section>
<section id="omitted-variable-bias-1" class="slide level2">
<h2>Omitted variable bias</h2>
<blockquote>
<p>Bias that occurs in statistical models when a relevant variable is not included in the model.</p>
</blockquote>
<div class="fragment">
<p><br></p>
<p><span class="hi-red">Consequence:</span> Leads to the incorrect estimation of the relationships between variables, which may affect the reliability of the model’s predictions and inferences.</p>
<p><br></p>
</div>
<div class="fragment">
<p><span class="hii">Solution:</span> <span class="note"><em>“Control”</em></span> for the omitted variable(s).</p>
</div>
</section>
<section id="section-12" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Class funding (<span class="hi">U</span>) <span class="note">confounds</span> our estimates of smaller class sizes (<span class="hi">X</span>) on test scores (<span class="hi">Y</span>). <br> <br></p>

<img data-src="images/dag-xyu-02.png" class="quarto-figure quarto-figure-center r-stretch"><p><em>Any unobserved variable</em> that connects a <span class="note">backdoor path</span> between class size (<span class="hi">X</span>) and test scores (<span class="hi">Y</span>) will <span class="hi">bias</span> our <span class="note">point estimate</span> of <span class="math inline">\(\beta_1\)</span>.</p>
</section>
<section id="section-13" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p>Class funding (<span class="hi">U</span>) <span class="note">confounds</span> our estimates of smaller class sizes (<span class="hi">X</span>) on test scores (<span class="hi">Y</span>). Including data on school funding (<span class="hi">U</span>) in a multiple linear regression allows us to close this backdoor path.</p>

<img data-src="images/dag-xyu-03.png" class="quarto-figure quarto-figure-center r-stretch"><div class="fragment">
<p>With all backdoor paths closed, <span class="note">point estimates</span> of <span class="math inline">\(\beta_1\)</span> will no longer be biased and will return the population parameter of interest</p>
</div>
</section>
<section class="slide level2">

<div class="vertical-center">
<p><em>In a little more detail, we can derive the bias mathematically.</em></p>
</div>
</section>
<section id="omitted-variable-bias-2" class="slide level2">
<h2>Omitted Variable Bias</h2>
<p>Imagine we have a population model of the form:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \beta_2 Z_i + u_i
\]</span></p>
<p>where <span class="math inline">\(Z_i\)</span> is a relevant variable that is omitted from the model.</p>
<p>and suppose we estimate the following model:</p>
<p><span class="math display">\[
Y_i = \hat{\beta}_0 + \hat{\beta}_1 X_i + v_i
\]</span></p>
<p>where <span class="math inline">\(v_i\)</span> is the new error term that absorbs the effect of <span class="math inline">\(Z_i\)</span></p>
</section>
<section id="omitted-variable-bias-3" class="slide level2">
<h2>Omitted Variable Bias</h2>
<p>To derive the bias of <span class="math inline">\(\hat{\beta}_1\)</span>, we need to understand the relationship between <span class="math inline">\(Z_i\)</span> and <span class="math inline">\(X_i\)</span>. Assume that:</p>
<p><span class="math display">\[
Z_i = \gamma_0 + \gamma_1 X_i + \varepsilon_i
\]</span></p>
<p>where <span class="math inline">\(\varepsilon_i\)</span> is the part of <span class="math inline">\(Z_i\)</span> that is uncorrelated with <span class="math inline">\(X_i\)</span></p>
<div class="fragment">
<p><br></p>
<p>If we substitute <span class="math inline">\(Z_i\)</span> into the population model, we get:</p>
<p><span class="math display">\[
\begin{align*}
Y_i &amp;= \beta_0 + \beta_1 X_i + \beta_2 \left( \gamma_0 + \gamma_1 X_i + \varepsilon_i \right) + u_i \\
    &amp;= \beta_0 + \beta_2 \gamma_0 + \left( \beta_1 + \beta_2 \gamma_1 \right) X_i + \beta_2 \varepsilon_i + u_i
\end{align*}
\]</span></p>
</div>
</section>
<section id="omitted-variable-bias-4" class="slide level2 small">
<h2>Omitted Variable Bias</h2>
<p>We can rewrite this expression:</p>
<p><span class="math display">\[
\begin{align*}
Y_i &amp;= \beta_0 + \beta_1 X_i + \beta_2 \left( \gamma_0 + \gamma_1 X_i + \varepsilon_i \right) + u_i \\
    &amp;= \beta_0 + \beta_2 \gamma_0 + \left( \beta_1 + \beta_2 \gamma_1 \right) X_i + \beta_2 \varepsilon_i + u_i
\end{align*}
\]</span></p>
<p>as:</p>
<p><span class="math display">\[
Y_i = \widehat{\beta}_0 + \widehat{\beta}_1 X_i + v_i
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\widehat{\beta}_0 = \beta_0 + \beta_2 \gamma_0\)</span></li>
<li><span class="math inline">\(\widehat{\beta}_1 = \beta_1 + \beta_2 \gamma_1\)</span></li>
<li><span class="math inline">\(v_i = \beta_2 \varepsilon_i + u_i\)</span></li>
</ul>
<p>Thus, we can see how <span class="math inline">\(Z_i\)</span> will bias our estimate of <span class="math inline">\(\beta_1\)</span></p>
</section>
<section id="omitted-variable-bias-5" class="slide level2">
<h2>Omitted Variable Bias</h2>
<p>Recall that we define the bias of an estimator as:</p>
<p><span class="math display">\[
\mathop{\text{Bias}}_\theta \left( W \right) = \mathop{\boldsymbol{E}}\left[ W \right] - \theta
\]</span></p>
<div class="fragment">
<p>The bias of the estimator <span class="math inline">\(\hat{\beta}_1\)</span> is given by:</p>
<p><span class="math display">\[
\begin{align*}
\mathop{\text{Bias}}_{\beta_1} \left( \hat{\beta}_1 \right) &amp;= \mathop{\boldsymbol{E}}\left[ \hat{\beta}_1 \right] - \beta_1 \\
&amp;= \mathop{\boldsymbol{E}}\left[ \beta_1 + \beta_2 \gamma_1 \right] - \beta_1 \\
&amp;= \beta_2 \gamma_1
\end{align*}
\]</span></p>
</div>
</section>
<section id="omitted-variable-bias-6" class="slide level2">
<h2>Omitted Variable Bias</h2>
<p>Finally, we can write the bias of <span class="math inline">\(\hat{\beta}_1\)</span> in terms of the correlation between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Z_i\)</span>:</p>
<p><span class="math display">\[
\gamma_1 = \frac{\text{Cov}\left( X_i, Z_i \right)}{\text{Var}\left( X_i \right)}
\]</span></p>
<div class="fragment">
<p>Therefore, we can write the bias of <span class="math inline">\(\hat{\beta}_1\)</span> as:</p>
<p><span class="math display">\[
\mathop{\text{Bias}}_{\beta_1} \left( \hat{\beta}_1 \right) = \beta_2 \frac{\text{Cov}\left( X_i, Z_i \right)}{\text{Var}\left( X_i \right)}
\]</span></p>
</div>
</section>
<section id="signing-the-bias" class="slide level2">
<h2>Signing the Bias</h2>
<p>Sometimes we’re stuck with omitted variable bias.</p>
<p><span class="math display">\[
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \beta_2 \dfrac{ \mathop{\text{Cov}} \left( X_i,\, Z_i \right)}{\mathop{\text{Var}} \left( X_i \right)}
\]</span></p>
<p>When this happens, we can often at least know the direction of the bias.</p>
</section>
<section id="signing-the-bias-1" class="slide level2" data-visiblity="uncounted">
<h2>Signing the Bias</h2>
<p>Begin with</p>
<p><span class="math display">\[
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \beta_2 \dfrac{ \mathop{\text{Cov}} \left( X_i,\, Z_i \right)}{\mathop{\text{Var}} \left( X_i \right)}
\]</span></p>
<p>We know <span class="math inline">\(\color{#8FBCBB}{\mathop{\text{Var}} \left( X_i \right) &gt; 0}\)</span>. Suppose <span class="math inline">\(\color{#81A1C1}{\beta_2 &gt; 0}\)</span> and <span class="math inline">\(\color{#EBCB8B}{\mathop{\text{Cov}} \left( X_i,\,Z_i \right) &gt; 0}\)</span>. Then</p>
<div class="fragment">
<p><span class="math display">\[
\begin{align}
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \color{#81A1C1}{(+)} \dfrac{\color{#EBCB8B}{(+)}}{\color{#8FBCBB}{(+)}} \implies \mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] &gt; \beta_1
\end{align}
\]</span> ∴ In this case, OLS is <strong>biased upward</strong> (estimates are too large).</p>
</div>
<div class="fragment">
<p><span class="math display">\[
\begin{matrix}
\enspace &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&gt; 0} &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&lt; 0} \\
\color{#81A1C1}{\beta_2 &gt; 0} &amp; \text{Upward} &amp;  \\
\color{#81A1C1}{\beta_2 &lt; 0} &amp;  &amp;
\end{matrix}
\]</span></p>
</div>
</section>
<section id="signing-the-bias-2" class="slide level2" data-visiblity="uncounted">
<h2>Signing the Bias</h2>
<p>Begin with</p>
<p><span class="math display">\[
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \beta_2 \dfrac{ \mathop{\text{Cov}} \left( X_i,\, Z_i \right)}{\mathop{\text{Var}} \left( X_i \right)}
\]</span></p>
<p>We know <span class="math inline">\(\color{#8FBCBB}{\mathop{\text{Var}} \left( X_i \right) &gt; 0}\)</span>. Suppose <span class="math inline">\(\color{#81A1C1}{\beta_2 &lt; 0}\)</span> and <span class="math inline">\(\color{#EBCB8B}{\mathop{\text{Cov}} \left( X_i,\,Z_i \right) &gt; 0}\)</span>. Then</p>
<div class="fragment">
<p><span class="math display">\[
\begin{align}
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \color{#81A1C1}{(-)} \dfrac{\color{#EBCB8B}{(+)}}{\color{#8FBCBB}{(+)}} \implies \mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] &lt; \beta_1
\end{align}
\]</span> ∴ In this case, OLS is <strong>biased downward</strong> (estimates are too small).</p>
<p><span class="math display">\[
\begin{matrix}
\enspace &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&gt; 0} &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&lt; 0} \\
\color{#81A1C1}{\beta_2 &gt; 0} &amp; \text{Upward} &amp;  \\
\color{#81A1C1}{\beta_2 &lt; 0} &amp; \text{Downward} &amp;
\end{matrix}
\]</span></p>
</div>
</section>
<section id="signing-the-bias-3" class="slide level2" data-visiblity="uncounted">
<h2>Signing the Bias</h2>
<p>Begin with</p>
<p><span class="math display">\[
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \beta_2 \dfrac{ \mathop{\text{Cov}} \left( X_i,\, Z_i \right)}{\mathop{\text{Var}} \left( X_i \right)}
\]</span></p>
<p>We know <span class="math inline">\(\color{#8FBCBB}{\mathop{\text{Var}} \left( X_i \right) &gt; 0}\)</span>. Suppose <span class="math inline">\(\color{#81A1C1}{\beta_2 &gt; 0}\)</span> and <span class="math inline">\(\color{#EBCB8B}{\mathop{\text{Cov}} \left( X_i,\,Z_i \right) &lt; 0}\)</span>. Then</p>
<p><span class="math display">\[
\begin{align}
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \color{#81A1C1}{(+)} \dfrac{\color{#EBCB8B}{(-)}}{\color{#8FBCBB}{(+)}} \implies \mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] &lt; \beta_1
\end{align}
\]</span> ∴ In this case, OLS is <strong>biased downward</strong> (estimates are too small).</p>
<p><span class="math display">\[
\begin{matrix}
\enspace &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&gt; 0} &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&lt; 0} \\
\color{#81A1C1}{\beta_2 &gt; 0} &amp; \text{Upward} &amp; \text{Downward} \\
\color{#81A1C1}{\beta_2 &lt; 0} &amp; \text{Downward} &amp;
\end{matrix}
\]</span></p>
</section>
<section id="signing-the-bias-4" class="slide level2" data-visiblity="uncounted">
<h2>Signing the Bias</h2>
<p>Begin with</p>
<p><span class="math display">\[
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \beta_2 \dfrac{ \mathop{\text{Cov}} \left( X_i,\, Z_i \right)}{\mathop{\text{Var}} \left( X_i \right)}
\]</span></p>
<p>We know <span class="math inline">\(\color{#8FBCBB}{\mathop{\text{Var}} \left( X_i \right) &gt; 0}\)</span>. Suppose <span class="math inline">\(\color{#81A1C1}{\beta_2 &lt; 0}\)</span> and <span class="math inline">\(\color{#EBCB8B}{\mathop{\text{Cov}} \left( X_i,\,Z_i \right) &lt; 0}\)</span>. Then</p>
<p><span class="math display">\[
\begin{align}
\mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] = \beta_1 + \color{#81A1C1}{(-)} \dfrac{\color{#EBCB8B}{(-)}}{\color{#8FBCBB}{(+)}} \implies \mathop{\boldsymbol{E}} \left[ \hat{\beta}_1 \right] &gt; \beta_1
\end{align}
\]</span> ∴ In this case, OLS is <strong>biased upward</strong> (estimates are too large).</p>
<p><span class="math display">\[
\begin{matrix}
\enspace &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&gt; 0} &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&lt; 0} \\
\color{#81A1C1}{\beta_2 &gt; 0} &amp; \text{Upward} &amp; \text{Downward} \\
\color{#81A1C1}{\beta_2 &lt; 0} &amp; \text{Downward} &amp; \text{Upward}
\end{matrix}
\]</span></p>
</section>
<section id="signing-the-bias-5" class="slide level2">
<h2>Signing the Bias</h2>
<p>Thus, in cases where we have a sense of</p>
<ol type="1">
<li><p>the sign of <span class="math inline">\(\mathop{\text{Cov}} \left( X_i,\,Z_i \right)\)</span></p></li>
<li><p>the sign of <span class="math inline">\(\beta_2\)</span></p></li>
</ol>
<p>we know in which direction bias pushes our estimates.</p>
<p><strong>Direction of Bias</strong></p>
<p><span class="math display">\[
\begin{matrix}
\enspace &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&gt; 0} &amp; \color{#EBCB8B}{\text{Cov}(X_i,\,Z_i)&lt; 0} \\
\color{#81A1C1}{\beta_2 &gt; 0} &amp; \text{Upward} &amp; \text{Downward} \\
\color{#81A1C1}{\beta_2 &lt; 0} &amp; \text{Downward} &amp; \text{Upward}
\end{matrix}
\]</span></p>
</section></section>
<section>
<section id="multiple-linear-regression" class="title-slide slide level1 inverse note center">
<h1>Multiple Linear Regression</h1>

</section>
<section id="multiple-linear-regression-1" class="slide level2">
<h2>Multiple linear regression</h2>
<p><span class="note">Simple linear regression</span> features one <span class="hi">dependent variable</span> and one <span class="hii">independent variable</span>:</p>
<p><span class="math display">\[
\color{#434C5E}{Y_i} = \beta_0 + \beta_1 \color{"#81A1C1"}{X_i} + u_i
\]</span></p>
<p><span class="note">Multiple linear regression</span> features one <span class="hi">dependent variable</span> and multiple <span class="hii">independent variables</span>:</p>
<p><span class="math display">\[
\color{#434C5E}{Y_i} = \beta_0 + \beta_1 \color{"#81A1C1"}{X_{1i}} + \beta_2 \color{"#81A1C1"}{X_{2i}} + \cdots + \beta_{k} \color{"#81A1C1"}{X_{ki}} + u_i
\]</span></p>
<div class="fragment">
<p>This serves more than one purpose. Multiple <span class="hii">independent variables</span> improves predictions, avoids <span class="hi-red">OVB</span>, and better explains variation in <span class="math inline">\(Y\)</span>.</p>
</div>
</section>
<section id="simple-linear-regression" class="slide level2">
<h2>Simple Linear Regression</h2>

<img data-src="images/multi-scatter-01.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="add-dimension-rightarrow-per-student-expenditure" class="slide level2">
<h2>Add Dimension <span class="math inline">\(\rightarrow\)</span> Per Student Expenditure</h2>

<img data-src="images/multi-scatter-02.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="multiple-linear-regression-ex." class="slide level2">
<h2>Multiple Linear Regression <span class="ex">Ex.</span></h2>
<p>If we ignore per student expenditure (aka our original simple regression)</p>
<p><span class="math display">\[
\text{Scores}_i = \beta_0 + \beta_1 \text{Class Size}_i + u_i
\]</span></p>

<img data-src="images/single-reg-results.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="multiple-linear-regression-ex.-1" class="slide level2">
<h2>Multiple Linear Regression <span class="ex">Ex.</span></h2>
<p>Controlling for <span class="hi">school funding</span></p>
<p><span class="math display">\[
\text{Scores}_i = \beta_0 + \beta_1 \text{Class Size}_i + \text{Expenditure}_i+ u_i
\]</span></p>

<img data-src="images/multi-reg-results.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="ols-estimation" class="slide level2">
<h2>OLS Estimation</h2>
<p><span class="note">Residuals</span> are now defined as:</p>
<div class="fragment">
<p><span class="math display">\[
\hat{u}_i = Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_{1i} - \hat{\beta}_2 X_{2i} - \cdots - \hat{\beta}_{k} X_{ki}
\]</span></p>
</div>
<div class="fragment">
<p>As with SLR, OLS minimizes the sum of squared residuals (<span class="hi-orange">RSS</span>).</p>
</div>
<div class="fragment">
<p><span class="math display">\[
\begin{align*}
  \color{#D08770}{RSS} &amp;= \sum_{i = 1}^{n} (Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_{1i} - \hat{\beta}_2 X_{2i} - \cdots - \hat{\beta}_{k} X_{ki})^2 \\
                        &amp;= \color{#D08770}{\sum_{i=1}^n \hat{u}_i^2}
\end{align*}
\]</span></p>
<p>which is a familiar expression.</p>
</div>
</section>
<section id="ols-estimation-1" class="slide level2">
<h2>OLS Estimation</h2>
<p>To obtain <span class="note">point estimates</span>:</p>
<p><span class="math display">\[
\min_{\hat{\beta}_0,\, \hat{\beta}_1,\, \dots \, \hat{\beta}_k} \quad \color{#D08770}{\sum_{i=1}^n \hat{u}_i^2}
\]</span></p>
<ul>
<li>Take partial derivatives of RSS with respect to each <span class="math inline">\(\hat{\beta}\)</span></li>
<li>Set each derivative equal to zero</li>
<li>Solve the system of <span class="math inline">\(k+1\)</span> equations<sup>1</sup>.</li>
</ul>
<div class="fragment">
<p>The algebra is cumbersome. We let <span class="hi">R</span> do the heavy lifting.</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn1"><p><span class="math inline">\(k+1\)</span> due to the intercept.</p></li></ol></aside></section>
<section id="coefficient-interpretation" class="slide level2">
<h2>Coefficient Interpretation</h2>
<p><span class="hi">Model</span></p>
<p><span class="math display">\[
\color{}{Y_i} = \beta_0 + \beta_1 \color{}{X_{1i}} + \beta_2 \color{}{X_{2i}} + \cdots + \beta_{k} \color{}{X_{ki}} + u_i
\]</span></p>
<p><span class="hi">Interpretation</span></p>
<ul>
<li>The intercept <span class="math inline">\(\hat{\beta}_0\)</span> is the average value of <span class="math inline">\(Y_i\)</span> when all of the independent variables are equal to zero.</li>
<li>Slope parameters <span class="math inline">\(\hat{\beta}_1, \dots, \hat{\beta}_{k}\)</span> give us the change in <span class="math inline">\(Y_i\)</span> from a one-unit change in <span class="math inline">\(X_j\)</span>, holding the other <span class="math inline">\(X\)</span> variables constant.</li>
</ul>
</section>
<section id="algebraic-properties-of-ols" class="slide level2">
<h2>Algebraic properties of OLS</h2>
<p>The OLS first-order conditions yield the same properties as before.</p>
<p><br></p>
<p><span class="note">1.</span> Residuals sum to zero: <span class="math inline">\(\sum_{i=1}^n \hat{u_i} = 0\)</span>.</p>
<p><span class="note">2.</span> The sample covariance <span class="math inline">\(X_i\)</span> and the <span class="math inline">\(\hat{u_i}\)</span> is zero.</p>
<p><span class="note">3.</span> The point <span class="math inline">\((\bar{X_1}, \bar{X_2}, \dots, \bar{X_k}, \bar{Y})\)</span> is on the fitted regression “line.”</p>
</section>
<section id="goodness-of-fit" class="slide level2">
<h2>Goodness of fit</h2>
<p>Fitted values are defined similarly:</p>
<p><span class="math display">\[
\hat{Y_i} = \hat{\beta}_0 + \hat{\beta}_1 X_{1i} + \hat{\beta}_2 X_{2i} + \cdots + \hat{\beta}_{k} X_{ki}
\]</span></p>
<p>The formula for <span class="math inline">\(R^2\)</span> is the same as before:</p>
<p><span class="math display">\[
R^2 =\frac{\sum(\hat{Y_i}-\bar{Y})^2}{\sum(Y_i-\bar{Y})^2}
\]</span></p>
</section>
<section id="goodness-of-fit-1" class="slide level2">
<h2>Goodness of fit</h2>
<p>We can describe the variation explain in <span class="math inline">\(Y\)</span> with venn diagrams</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/venn-model-01.png" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">

</div></div>
</section>
<section id="goodness-of-fit-2" class="slide level2">
<h2>Goodness of fit</h2>
<p>We can describe the variation explain in <span class="math inline">\(Y\)</span> with venn diagrams</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/venn-model-02.png" class="quarto-figure quarto-figure-center" height="450"></p>
</figure>
</div>
</div><div class="column vertical-center" style="width:50%;">
<p>As we add more variables, we are able to explain more “chunks” of the variation in <span class="math inline">\(y\)</span></p>
</div></div>
</section>
<section id="section-14" class="slide level2">
<h2></h2>
<div class="vertical-center">
<p><span class="hi-red">Problem:</span> As we add variables to our model, <span class="math inline">\(R^2\)</span> <em>mechanically</em> increases.</p>
<p><br></p>
<p><span class="fragment">Let me show you this <span class="hi-red">problem</span> with a <span class="hii">simulation</span></span></p>
</div>
</section>
<section id="section-15" class="slide level2">
<h2></h2>
<div class="vertical-center">
<p>Simulate a dataset of 10,000 observations on <span class="math inline">\(y\)</span> and 1,000 random <span class="math inline">\(x_k\)</span> variables, where</p>
<p><span class="math display">\[
y \perp x_k \quad \forall x_k \; \text{s.t.} \; k = 1, 2, \dots, 1000
\]</span></p>
<p><br></p>
<p><span class="fragment">We have 1,000 independent variables that are <span class="note">independent</span> to the dependent variable.</span> <span class="fragment">Each <span class="math inline">\(x_k\)</span> has no relationship to <span class="math inline">\(y\)</span> whatsoever.</span></p>
</div>
</section>
<section class="slide level2">

<p><span class="hi-red">Problem:</span> As we add variables to our model, <span class="math inline">\(\color{#314f4f}{R^2}\)</span> <em>mechanically</em> increases.</p>
<p><span class="mono">Pseudo-code:</span></p>
<div class="pseudocode">
<p>Generate 10,000 obs. on <span class="math inline">\(y\)</span></p>
<p>Generate 10,000 obs. on variables <span class="math inline">\(x_1\)</span> through <span class="math inline">\(x_{1000}\)</span></p>
<p><br></p>
<p>Regressions:</p>
<ul>
<li>LM<sub>1</sub>: Regress <span class="math inline">\(y\)</span> of <span class="math inline">\(x_1\)</span>; record <span class="math inline">\(R^2\)</span></li>
<li>LM<sub>2</sub>: Regress <span class="math inline">\(y\)</span> of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>; record <span class="math inline">\(R^2\)</span></li>
<li>…</li>
<li>LM<sub>1000</sub>: Regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, …, <span class="math inline">\(x_{1000}\)</span>; record <span class="math inline">\(R^2\)</span></li>
</ul>
</div>
</section>
<section id="section-16" class="slide level2">
<h2></h2>
<p><span class="hi-red">Problem:</span> As we add variables to our model, <span class="math inline">\(R^2\)</span> <em>mechanically</em> increases.</p>
<p><br></p>

<img data-src="images/more-vars-r2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-17" class="slide level2" data-visibility="uncounted">
<h2></h2>
<p><span class="hi-red">Problem:</span> As we add variables to our model, <span class="math inline">\(R^2\)</span> <em>mechanically</em> increases.</p>
<p><span class="hii">One solution:</span> Penalize for the number of variables, <em>e.g.</em>, adjusted <span class="math inline">\(R^2\)</span>:</p>

<img data-src="images/adjusted-r2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="goodness-of-fit-3" class="slide level2">
<h2>Goodness of fit</h2>
<p><span class="hi-red">Problem:</span> As we add variables to our model, <span class="math inline">\(R^2\)</span> <em>mechanically</em> increases.</p>
<p><span class="hii">One solution:</span> Penalize for the number of variables, <em>e.g.</em>, adjusted <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
\bar{R}^2 = 1 - \dfrac{\sum_i \left( Y_i - \hat{Y}_i \right)^2/(n-k-1)}{\sum_i \left( Y_i - \bar{Y} \right)^2/(n-1)}
\]</span></p>
<p><br><br></p>
<p><em>Note:</em> Adjusted <span class="math inline">\(R^2\)</span> need not be between 0 and 1.</p>
</section>
<section id="multiple-regression" class="slide level2">
<h2>Multiple regression</h2>
<p>There are <span class="hi">tradeoffs</span> to remember as we add/remove variables:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="hi-red">Fewer variables</span></p>
<ul>
<li>Explains less variation in <span class="math inline">\(y\)</span></li>
<li>Provide simple interpretations and visualizations</li>
<li>More worried about omitted-variable bias</li>
</ul>
</div><div class="column" style="width:50%;">
<p><span class="hii">More variables</span></p>
<ul>
<li>More likely to find <em>spurious</em> relationships<sup>1</sup></li>
<li>More difficult interpretation</li>
<li>The <span class="note">variance</span> of our <span class="note">point estimates</span> will be bigger</li>
<li>We still might have omitted-variable bias</li>
</ul>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn2"><p>Spurious meaning <em>statistically significant</em> by coincidence—not reflective of true, population-level relationship</p></li></ol></aside></section>
<section id="multiple-regression-1" class="slide level2" data-visibility="uncounted">
<h2>Multiple regression</h2>
<p>There are <span class="hi">tradeoffs</span> to remember as we add/remove variables:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="hi-red">Fewer variables</span></p>
<ul>
<li>Explains less variation in <span class="math inline">\(y\)</span></li>
<li>Provide simple interpretations and visualizations</li>
<li>More worried about omitted-variable bias</li>
</ul>
</div><div class="column" style="width:50%;">
<p><span class="hii">More variables</span></p>
<ul>
<li>More likely to find <em>spurious</em> relationships<sup>1</sup></li>
<li>More difficult interpretation</li>
<li><span class="hi">The variance of our point estimates will be bigger</span></li>
<li>We still might have omitted-variable bias</li>
</ul>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn3"><p>Spurious meaning <em>statistically significant</em> by coincidence—not reflective of true, population-level relationship</p></li></ol></aside></section></section>
<section>
<section id="multicollinearity" class="title-slide slide level1 inverse note center">
<h1>Multicollinearity</h1>

</section>
<section id="ols-variances" class="slide level2">
<h2>OLS variances</h2>
<p>Multiple regression model:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \cdots + \beta_{k} X_{ki} + u_i
\]</span></p>
<p>It can be shown that the estimator <span class="math inline">\(\hat{\beta}_j\)</span> on independent variable <span class="math inline">\(X_j\)</span> is:</p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta_j} \right) = \dfrac{\sigma^2}{\left( 1 - R^2_j \right)\sum_{i=1}^n \left( X_{ji} - \bar{X}_j \right)^2},
\]</span></p>
<p>where <span class="math inline">\(R^2_j\)</span> is the <span class="math inline">\(R^2\)</span> from a regression of <span class="math inline">\(X_j\)</span> on the other independent variables and the intercept</p>
</section>
<section id="ols-variances-1" class="slide level2">
<h2>OLS variances</h2>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta_j} \right) = \dfrac{{\color{#81A1C1}\sigma^2}}{\left( 1 - \color{#81A1C1}{R_j^2} \right)\color{#BF616A}{\sum_{i=1}^n \left( X_{ji} - \bar{X}_j \right)^2}},
\]</span></p>
<p><span class="hi">Moving parts:</span></p>
<div class="small">
<p><span class="fragment"><span class="note">1.</span> <span class="hi">Error variance:</span> As <span class="math inline">\(\color{#81A1C1}{\sigma^2}\)</span> increases, <span class="math inline">\(Var(\hat{\beta}_j)\)</span> increases</span></p>
<p><span class="fragment"><span class="note">2.</span> <span class="hi">Total variation in <span class="math inline">\(X_j\)</span>:</span> As <span class="math inline">\(\color{#BF616A}{\sum_{i=1}^n \left( X_{ji} - \bar{X}_j \right)^2}\)</span> increases, <span class="math inline">\(Var(\hat{\beta}_j)\)</span> decreases</span></p>
<p><span class="fragment"><span class="note">3.</span> <span class="hi">Relationship across <span class="math inline">\(X_i\)</span>:</span> As <span class="math inline">\(\color{#81A1C1}{R_j^2}\)</span> increases, <span class="math inline">\(Var(\hat{\beta}_j)\)</span> increases</span></p>
</div>
<p><br></p>
<div class="fragment">
<p><span class="note">3.</span> is better known as <span class="note">Multicollinearity</span></p>
</div>
</section>
<section id="multicollinearity-1" class="slide level2">
<h2>Multicollinearity</h2>
<blockquote>
<p>Case in which two or more independent variables in a regression model are highly correlated.</p>
</blockquote>
<div class="fragment">
<p><br></p>
<p>One independent variable can predict most of the variation in another independent variable.</p>
<p><br></p>
</div>
<div class="fragment">
<p><span class="note">Multicollinearity</span> leads to <span class="hi">imprecise</span> estimates. <span class="fragment">Becomes difficult to distinguish between individual effects from of independent variables.</span></p>
</div>
</section>
<section id="ols-assumptions" class="slide level2">
<h2>OLS Assumptions</h2>
<p>Classical assumptions for OLS change slightly for multiple OLS</p>
<p><span class="note">A1.</span> <span class="hi">Linearity:</span> The population relationship is <span class="note"><em>linear in parameters</em></span> with an additive error term.</p>
<p><span class="note">A2.</span> <span class="hi"><span class="hi">Sample Variation:</span> No <span class="math inline">\(X\)</span> variable is a perfect linear combination of the others</span></p>
<p><span class="note">A3.</span> <span class="hi">Exogeniety:</span> The <span class="math inline">\(X\)</span> variable is <span class="note">exogenous</span></p>
<p><span class="note">A4.</span> <span class="hi">Homoskedasticity:</span> The error term has the same variance for each value of the independent variable</p>
<p><span class="note">A5.</span> <span class="hi">Non-autocorrelation:</span> The values of error terms have independent distributions</p>
</section>
<section id="perfect-collinearity" class="slide level2">
<h2>Perfect Collinearity</h2>
<blockquote>
<p>Case in which two or more independent variables in a regression model are perfectly correlated.</p>
</blockquote>
<p><span class="ex">Ex.</span> 2016 Election</p>
<p>OLS simultaneously cannot estimate parameters for <span class="mono">white</span> and <span class="mono">nonwhite</span>.</p>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/multico-01.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
<p><span class="mono">R</span> drops perfectly collinear variables for you.</p>
</div>
</section>
<section id="multicollinearity-ex." class="slide level2">
<h2>Multicollinearity <span class="ex">Ex.</span></h2>
<p>Suppose that we want to understand the relationship between crime rates and poverty rates in US cities. We could estimate the model</p>
<p><span class="math display">\[
\text{Crime}_i = \beta_0 + \beta_1 \text{Poverty}_i + \beta_2 \text{Income}_i + u_i
\]</span></p>
<div class="fragment">
<p>Before obtaining standard errors, we need:</p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta}_1 \right) = \dfrac{\sigma^2}{\left( 1 - R^2_1 \right)\sum_{i=1}^n \left( \text{Poverty}_{i} - \overline{\text{Poverty}} \right)^2}
\]</span></p>
</div>
<div class="fragment">
<p><span class="math inline">\(R^2_1\)</span> is the <span class="math inline">\(R^2\)</span> from a regression of poverty on median income:</p>
<p><span class="math display">\[
\text{Poverty}_i = \gamma_0 + \gamma_1 \text{Income}_i + v_i
\]</span></p>
</div>
</section>
<section id="multicollinearity-2" class="slide level2">
<h2>Multicollinearity</h2>
<p><span class="hi">Scenario 1:</span> <span class="math inline">\(\text{Income}_i\)</span> explains most variation in <span class="math inline">\(\text{Poverty}_i\)</span>, then <span class="math inline">\(R^2_1 \rightarrow 1\)</span></p>
<ul>
<li>Violates the <span class="note"><em>no perfect collinearity</em></span> assumption</li>
</ul>
<div class="fragment">
<p><span class="hi">Scenario 2:</span> If <span class="math inline">\(\text{Income}_i\)</span> explains no variation in <span class="math inline">\(\text{Poverty}_i\)</span>, then <span class="math inline">\(R^2_1 = 0\)</span></p>
</div>
<div class="fragment">
<p><span class="note">Q.</span> <em>In which scenario is the variance of the poverty coefficient smaller?</em></p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta}_1 \right) = \dfrac{\sigma^2}{\left( 1 - R^2_1 \right)\sum_{i=1}^n \left( \text{Poverty}_{i} - \overline{\text{Poverty}} \right)^2}
\]</span></p>
</div>
<div class="fragment">
<p><span class="note">A.</span> <span class="hi">Scenario 2.</span></p>
</div>
</section>
<section id="multicollinearity-3" class="slide level2">
<h2>Multicollinearity</h2>
<p>As the relationships between the variables increase, <span class="math inline">\(R^2_j\)</span> increases.</p>
<p>For high <span class="math inline">\(R^2_j\)</span>, <span class="math inline">\(\mathop{\text{Var}} \left( \hat{\beta_j} \right)\)</span> is large:</p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta_j} \right) = \dfrac{\sigma^2}{\left( 1 - R^2_j \right)\sum_{i=1}^n \left( X_{ji} - \bar{X}_j \right)^2}
\]</span></p>
<div class="fragment">
<ul>
<li>Some view multicollinearity as a “problem” to be solved.</li>
<li>Either increase power (<span class="math inline">\(n\)</span>) or drop correlated variables</li>
<li><span class="note">Warning:</span> Dropping variables can generate omitted variable bias.</li>
</ul>
</div>
</section>
<section id="irrelevant-variables" class="slide level2">
<h2>Irrelevant Variables</h2>
<p>Suppose that the true relationship between birth weight and <em>in utero</em> exposure to toxic air pollution is</p>
<p><span class="math display">\[
(\text{Birth Weight})_i = \beta_0 + \beta_1 \text{Pollution}_i + u_i
\]</span></p>
<div class="fragment">
<p>Suppose that an “analyst” estimates</p>
<p><span class="math display">\[
(\text{Birth Weight})_i = \tilde{\beta_0} + \tilde{\beta_1} \text{Pollution}_i + \tilde{\beta_2}\text{NBA}_i + u_i
\]</span></p>
</div>
<div class="fragment">
<p>One can show that <span class="math inline">\(\mathop{\mathbb{E}} \left( \hat{\tilde{\beta_1}} \right) = \beta_1\)</span> (<em>i.e.</em>, <span class="math inline">\(\hat{\tilde{\beta_1}}\)</span> is unbiased).</p>
<p>However, the variances of <span class="math inline">\(\hat{\tilde{\beta_1}}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> differ.</p>
</div>
</section>
<section id="irrelevant-variables-1" class="slide level2">
<h2>Irrelevant Variables</h2>

<img data-src="images/irrelevant-vars.png" class="quarto-figure quarto-figure-center r-stretch"><p>We can reasonably say that the NBA has no direct impact on birth weight, so it is doing more damage to the model than helping</p>
</section>
<section id="irrelevant-variables-2" class="slide level2">
<h2>Irrelevant Variables</h2>
<p>The variance of <span class="math inline">\(\hat{\beta}_1\)</span> from estimating the “true model” is</p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\beta_1} \right) = \dfrac{\sigma^2}{\sum_{i=1}^n \left( \text{Pollution}_{i} - \overline{\text{Pollution}} \right)^2}
\]</span></p>
<p>The variance of <span class="math inline">\(\hat{\tilde\beta}_1\)</span> from estimating the model with the irrelevant variable is</p>
<p><span class="math display">\[
\mathop{\text{Var}} \left( \hat{\tilde{\beta_1}} \right) = \dfrac{\sigma^2}{\left( 1 - R^2_1 \right)\sum_{i=1}^n \left( \text{Pollution}_{i} - \overline{\text{Pollution}} \right)^2}
\]</span></p>
</section>
<section id="irrelevant-variables-3" class="slide level2">
<h2>Irrelevant Variables</h2>
<p>Notice that <span class="math inline">\(\mathop{\text{Var}} \left( \hat{\beta_1} \right) \leq \mathop{\text{Var}} \left( \hat{\tilde{\beta_1}} \right)\)</span> since,</p>
<p><span class="math display">\[
\sum_{i=1}^n \left( \text{Poll.}_{i} - \overline{\text{Poll.}} \right)^2
\geq
\left( 1 - R^2_1 \right)\sum_{i=1}^n \left( \text{Poll.}_{i} - \overline{\text{Poll.}} \right)^2
\]</span></p>
<div class="fragment">
<p><br></p>
<p>A tradeoff exists when including more control variables. <span class="fragment">Make sure you have good reason for your controls because including irrelevant control variables <span class="hii">increase</span> variances</span></p>
</div>
</section>
<section id="estimating-error-variance" class="slide level2">
<h2>Estimating Error Variance</h2>
<p>We cannot observe <span class="math inline">\(\sigma^2\)</span>, so we must estimate it using the residuals from an estimated regression:</p>
<p><span class="math display">\[
s_u^2 = \dfrac{\sum_{i=1}^n \hat{u}_i^2}{n - k - 1}
\]</span></p>
<ul>
<li><span class="math inline">\(k+1\)</span> is the number of parameters (one “slope” for each <span class="math inline">\(X\)</span> variable and an intercept).</li>
<li><span class="math inline">\(n - k - 1\)</span> <span class="mono">=</span> degrees of freedom.</li>
<li>Using the first 5 OLS assumptions, one can prove that <span class="math inline">\(s_u^2\)</span> is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>.</li>
</ul>
</section>
<section id="standard-errors" class="slide level2">
<h2>Standard Errors</h2>
<p>The formula for the standard error is the square root of <span class="math inline">\(\mathop{\text{Var}} \left( \hat{\beta_j} \right)\)</span>:</p>
<p><span class="math display">\[
\mathop{\text{SE}}(\hat{\beta_j}) = \sqrt{ \frac{s^2_u}{(  1 - R^2_j ) \sum_{i=1}^n ( X_{ji} - \bar{X}_j )^2} }
\]</span></p>
</section></section>
<section>
<section id="f-tests" class="title-slide slide level1 inverse note center">
<h1>F-Tests</h1>

</section>
<section id="f-tests-1" class="slide level2">
<h2><em>F</em> Tests</h2>
<p><span class="hi">t tests</span> allow us to test simple hypotheses involving a <span class="hii">single parameter</span>.</p>
<ul>
<li><em>e.g.</em>, <span class="math inline">\(\beta_1 = 0\)</span> or <span class="math inline">\(\beta_2 = 1\)</span>.</li>
</ul>
<div class="fragment">
<p><span class="hi"><em>F</em> tests</span> allow us to test hypotheses that involve <span class="hp">multiple parameters</span>.</p>
<ul>
<li><em>e.g.</em>, <span class="math inline">\(\beta_1 = \beta_2\)</span> or <span class="math inline">\(\beta_3 + \beta_4 = 1\)</span>.</li>
</ul>
</div>
</section>
<section id="f-tests-2" class="slide level2">
<h2><em>F</em> Tests</h2>
<p><span class="ex">Ex.</span> Is money “fungible”?</p>
<p>Economists often say that “money is fungible.”</p>
<p>We might want to test whether money received as income actually has the same effect on consumption as money received from tax credits.</p>
<p><span class="math display">\[
\text{Consumption}_i = \beta_0 + \beta_1 \text{Income}_{i} + \beta_2 \text{Credit}_i + u_i
\]</span></p>
</section>
<section id="f-tests-3" class="slide level2">
<h2><em>F</em> Tests</h2>
<p><span class="ex">Ex.</span> Is money “fungible”?</p>
<p>We can write our null hypothesis as</p>
<p><span class="math display">\[
H_0:\: \beta_1 = \beta_2 \iff H_0 :\: \beta_1 - \beta_2 = 0
\]</span></p>
<p>Imposing the null hypothesis gives us a <span class="hi">restricted model</span></p>
<p><span class="math display">\[
\text{Consumption}_i = \beta_0 + \beta_1 \text{Income}_{i} + \beta_1 \text{Credit}_i + u_i
\]</span></p>
<p><span class="math display">\[
\text{Consumption}_i = \beta_0 + \beta_1 \left( \text{Income}_{i} + \text{Credit}_i \right) + u_i
\]</span></p>
</section>
<section id="f-tests-4" class="slide level2">
<h2><em>F</em> Tests</h2>
<p><span class="ex">Ex.</span> Is money “fungible”?</p>
<p>To test the null hypothesis <span class="math inline">\(H_o :\: \beta_1 = \beta_2\)</span> against <span class="math inline">\(H_a :\: \beta_1 \neq \beta_2\)</span>, <br>we use the <span class="math inline">\(F\)</span> statistic:</p>
<p><span class="math display">\[
\begin{align}
  F_{q,\,n-k-1} = \dfrac{\left(\text{RSS}_r - \text{RSS}_u\right)/q}{\text{RSS}_u/(n-k-1)}
\end{align}
\]</span></p>
<p>which (as its name suggests) follows the <span class="math inline">\(F\)</span> distribution with <span class="math inline">\(q\)</span> numerator degrees of freedom and <span class="math inline">\(n-k-1\)</span> denominator degrees of freedom.</p>
<p>Here, <span class="math inline">\(q\)</span> is the number of restrictions we impose via <span class="math inline">\(H_0\)</span>.</p>
</section>
<section id="f-tests-5" class="slide level2">
<h2><em>F</em> Tests</h2>
<p><span class="ex">Ex.</span> Is money “fungible”?</p>
<p>The term <span class="math inline">\(\text{RSS}_r\)</span> is the sum of squared residuals (RSS) from our <span class="hi">restricted model</span></p>
<p><span class="math display">\[
\text{Consumption}_i = \beta_0 + \beta_1 \left( \text{Income}_{i} + \text{Credit}_i \right) + u_i
\]</span></p>
<p>and <span class="math inline">\(\text{RSS}_u\)</span> is the sum of squared residuals (RSS) from our <span class="hi">unrestricted model</span></p>
<p><span class="math display">\[
\text{Consumption}_i = \beta_0 + \beta_1 \text{Income}_{i} + \beta_2 \text{Credit}_i + u_i
\]</span></p>
</section>
<section id="f-tests-6" class="slide level2">
<h2><em>F</em> Tests</h2>
<p>Finally, we compare our <span class="math inline">\(F\)</span>-statistic to a critical value of <span class="math inline">\(F\)</span> to test the null hypothesis.</p>
<p>If <span class="math inline">\(F\)</span> &gt; <span class="math inline">\(F_\text{crit}\)</span>, then reject the null hypothesis at the <span class="math inline">\(\alpha \times 100\)</span> percent level.</p>
<ul>
<li>Find <span class="math inline">\(F_\text{crit}\)</span> in a table using the desired significance level, numerator degrees of freedom, and denominator degrees of freedom.</li>
</ul>
<div class="fragment">
<p><span class="note">Aside:</span> Why are <span class="math inline">\(F\)</span>-statistics always positive?</p>
</div>
</section>
<section id="f-tests-7" class="slide level2">
<h2><em>F</em> Tests</h2>
<p>RSS is usually a large cumbersome number.</p>
<p><span class="hii">Alternative:</span> Calculate the <span class="math inline">\(F\)</span>-statistic using <span class="math inline">\(R^2\)</span>.</p>
<p><span class="math display">\[
\begin{align}
  F = \dfrac{\left(R^2_u - R^2_r\right)/q}{ (1 - R^2_u)/(n-k-1)}
\end{align}
\]</span></p>
<div class="fragment">
<p>Where does this come from?</p>
<div class="columns">
<div class="column" style="width:40%;">
<p><span class="math inline">\(\text{TSS} = \text{RSS} + \text{ESS}\)</span></p>
<p><span class="math inline">\(R^2 = \text{ESS}/\text{TSS}\)</span></p>
</div><div class="column" style="width:60%;">
<p><span class="math inline">\(\text{RSS}_r = \text{TSS}(1-R^2_r)\)</span></p>
<p><span class="math inline">\(\text{RSS}_u = \text{TSS}(1-R^2_u)\)</span></p>
</div></div>


</div>
</section></section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>EC320, Lecture 05 | Multi Variable Regression</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>