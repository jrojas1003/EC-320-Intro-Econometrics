---
name: exreg
---

---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

[Empirical question:]{.note}

: Does the number of on-campus police officers affect campus crime rates? If so, by how much?

. . .

<br>

Always plot your data first

---

## 

![](images/plotted-data.png)
---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

The scatter plot suggest that a _weak_ positive relationship exists

- A sample correlation of 0.14 confirms this

<br>

. . . 

_But correlation does not imply causation_

. . .

<br>

Lets estimate a statistical model 

---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

We express the relationship between a [dependent variable]{.hp} and an [independent variable]{.hii} as linear:

$$
{\text{Crime}_i} = \beta_0 + \beta_1 \text{Police}_i + u_i.
$$

- $\beta_0$ is the _intercept_ or constant.

- $\beta_1$ is the _slope coefficient_.

- $u_i$ is an _error term_ or disturbance term.

---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

The [intercept]{.hi-red} tells us the expected value of $\text{Crime}_i$ when $\text{Police}_i = 0$. 

$$
\text{Crime}_i = {\color{#BF616A} \beta_{0}} + \beta_1\text{Police}_i + u_i
$$

Usually not the focus of an analysis.

---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

The [slope coefficient]{.hi-red} tells us the expected change in $\text{Crime}_i$ when $\text{Police}_i$ increases by one. 

$$
 \text{Crime}_i = \beta_0 + {\color{#BF616A} \beta_1} \text{Police}_i + u_i
$$

"A one-unit increase in $\text{Police}_i$ is associated with a $\color{#BF616A}{\beta_1}$-unit increase in $\text{Crime}_i$."

. . .

Interpretation of this parameter is [crucial]{.hi}

. . .

Under certain (strong) assumptions^[Assumptions regarding the error term], $\color{#BF616A}{\beta_1}$ is the _effect of_ $X_i$ _on_ $Y_i$.

- Otherwise, it's the _association of_ $X_i$ _with_ $Y_i$.


---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

The [error term]{.hi-red} reminds us that $\text{Police}_i$ does not perfectly explain $Y_i$. 

$$
 \text{Crime}_i = \beta_0 + \beta_1\text{Police}_i + {\color{#BF616A} u_i}
$$

Represents all other factors that explain $\text{Crime}_i$.

- Useful mnemonic: pretend that $u$ stands for *"unobserved"* or *"unexplained."*


---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

How might we apply the simple linear regression model to our question about the effect of on-campus police on campus crime?

$$
 \text{Crime}_i = \beta_0 + \beta_1\text{Police}_i + u_i.
$$

- $\beta_0$ is the crime rate for colleges without police.
- $\beta_1$ is the increase in the crime rate for an additional police officer per 1000 students.

---

## [Ex.]{.ex} [Effect of police on crime]{.hi}

How might we apply the simple linear regression model to our question?

$$
 \text{Crime}_i = \beta_0 + \beta_1\text{Police}_i + u_i
$$

$\beta_0$ and $\beta_1$ are the unobserved population parameters we want

. . .

<br>

[We estimate]{.hii}

- $\hat{\beta_0}$ and $\hat{\beta_1}$ generate predictions of $\text{Crime}_i$ called $\widehat{\text{Crime}_i}$. 

- We call the predictions of the dependent variable [fitted values.]{.hi}

. . .

- Together, these trace a line: $\widehat{\text{Crime}_i} = \hat{\beta_0} + \hat{\beta_1}\text{Police}_i$.

---

##

::: {.vertical-center}
So, the question becomes, _how do I pick $\hat{\beta_0}$ and $\hat{\beta_1}$_
:::

---

##

Let's take some guesses: $\hat{\beta_0} = 60$ and $\hat{\beta}_{1} = -7$

![](images/int60-guess.png)

---

## 

Let's take some guesses: $\hat{\beta_0} = 30$ and $\hat{\beta}_{1} = 0$

![](images/int30-guess.png)

---

##

Let's take some guesses: $\hat{\beta_0} = 15.6$ and $\hat{\beta}_{1} = 7.94$

![](images/int15-guess.png)

---

## Residuals

Using $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ to make $\hat{y}_{i}$ generates misses.

<br><br>

:::: {.columns}

::: {.column width="33%"}
![](images/int60-resid.png)
[$\hat{\beta_0} = 60 \;$ Guess]{.h .align-center}
:::

::: {.column width="33%"}
![](images/int30-resid.png)
[$\hat{\beta_0} = 30 \;$ Guess]{.h .align-center}
:::

::: {.column width="33%"}
![](images/int15-resid.png)
[$\hat{\beta_0} = 15 \;$ Guess]{.h .align-center}
:::

::::

---

## Residuals Sum of Squares (RSS)

What if we picked an estimator that [minimizes]{.h} the residuals?

Why do we not minimize:

$$
    \sum_{i=1}^{n} \hat{u}_{i}^{2}
$$

so that the estimator makes fewer big misses?

This estimator, the [residual sum of squares (RSS)]{.hii}, is convenient because squared numbers are never negative so we can minimze an absolut sum of the residuals

[RSS]{.hii} will give bigger penalties to bigger residuals

---

## Minimizing RSS


We could test thousands of guesses of $\beta_0$ and $\beta_1$ an pick the pair the has the smallest RSS

We could painstakingly do that, and eventually figure out which one fits best.

Or... [We could just do a little math]{.fragment}
